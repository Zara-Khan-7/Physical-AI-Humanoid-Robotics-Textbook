---
sidebar_position: 3
slug: /sensors
title: سینسرز اور ادراک
description: روبوٹ اپنے ماحول کو کیسے محسوس اور سمجھتے ہیں
---

# سینسرز اور ادراک

## روبوٹ سینسنگ کا تعارف

جیسے انسان دنیا میں نیویگیٹ کرنے اور تعامل کرنے کے لیے حواس پر انحصار کرتے ہیں، روبوٹ اپنے ماحول کو سمجھنے کے لیے سینسرز پر انحصار کرتے ہیں۔ یہ باب ہیومنائڈ روبوٹکس میں استعمال ہونے والی مختلف سینسنگ modalities اور ادراک کے لیے سینسر ڈیٹا کی پراسیسنگ کا جائزہ لیتا ہے۔

## سینسرز کی اقسام

### پروپریوسیپٹو سینسرز

پروپریوسیپٹو سینسرز روبوٹ کی اندرونی حالت—اس کے اپنے جسم کی پوزیشن اور حرکت—کو ناپتے ہیں۔

#### جوائنٹ انکوڈرز

انکوڈرز جوائنٹ زاویے ناپتے ہیں اور روبوٹ کی configuration جاننے کے لیے ضروری ہیں۔

**انکوڈرز کی اقسام:**
- **انکریمینٹل انکوڈرز**: پوزیشن میں نسبتی تبدیلیاں ناپتے ہیں
- **ایبسولیوٹ انکوڈرز**: کسی بھی وقت مطلق پوزیشن فراہم کرتے ہیں
- **ریزولوشن**: فی چکر counts (CPR) میں ماپا جاتا ہے، عام طور پر 1000-10000+

**ایپلیکیشنز:**
- کنٹرول کے لیے جوائنٹ پوزیشن فیڈبیک
- differentiation کے ذریعے ویلوسیٹی کا تخمینہ
- فارورڈ کائنیمیٹکس کا حساب

#### انرشیل میژرمنٹ یونٹس (IMU)

IMUs اورینٹیشن اور acceleration ناپنے کے لیے متعدد سینسرز کو جوڑتے ہیں۔

**اجزاء:**
- **ایکسلرومیٹرز**: لکیری acceleration ناپتے ہیں (3-axis)
- **جائروسکوپس**: angular velocity ناپتے ہیں (3-axis)
- **میگنیٹومیٹرز**: مقناطیسی فیلڈ کی سمت ناپتے ہیں (اختیاری)

**6-DOF بمقابلہ 9-DOF IMUs:**
- 6-DOF: ایکسلرومیٹر + جائروسکوپ
- 9-DOF: ایکسلرومیٹر + جائروسکوپ + میگنیٹومیٹر

**اہم specifications:**
- سیمپلنگ ریٹ: 100-1000 Hz عام
- جائرو ڈرفٹ: 0.1-10 °/گھنٹہ
- ایکسلرومیٹر نوائز: 50-500 μg/√Hz

#### فورس/ٹارک سینسرز

یہ سینسرز قوتیں اور ٹارکز ناپتے ہیں، جو کے لیے اہم ہیں:
- ماحول سے رابطے کا پتہ لگانا
- manipulation فورس کو کنٹرول کرنا
- گراؤنڈ ری ایکشن فورسز ناپنا

**سٹرین گیج پر مبنی:**
سب سے عام قسم، میٹیریل کی شکل بدلنے پر الیکٹریکل resistance میں تبدیلی استعمال کرتی ہے۔

**6-Axis F/T سینسرز:**
تینوں فورس اجزاء (Fx, Fy, Fz) اور تینوں ٹارک اجزاء (Tx, Ty, Tz) ناپتے ہیں۔

### ایکسٹروسیپٹو سینسرز

ایکسٹروسیپٹو سینسرز بیرونی ماحول کو ناپتے ہیں۔

#### ویژن سسٹمز

**کیمرے کی اقسام:**

1. **RGB کیمرے**: رنگین تصاویر capture کرتے ہیں
   - ریزولوشن: VGA (640×480) سے 4K+
   - فریم ریٹ: 30-120 fps
   - ایپلیکیشنز: آبجیکٹ ریکگنیشن، ویژول سروونگ

2. **ڈیپتھ کیمرے**: اشیاء تک فاصلہ ناپتے ہیں
   - **سٹرکچرڈ لائٹ**: پیٹرن پروجیکٹ کریں اور distortion کا تجزیہ کریں (مثلاً Intel RealSense)
   - **ٹائم آف فلائٹ (ToF)**: روشنی کے سفر کا وقت ناپیں
   - **سٹیریو ویژن**: گہرائی کا حساب لگانے کے لیے دو کیمرے استعمال کریں

3. **ایونٹ کیمرے**: asynchronously روشنی کی تبدیلیوں کا پتہ لگاتے ہیں
   - بہت زیادہ ٹیمپورل ریزولوشن (μs)
   - زیادہ ڈائنامک رینج
   - کم latency

**کیمرا specifications:**
| پیرامیٹر | عام رینج |
|-----------|---------------|
| ریزولوشن | 640×480 سے 4096×2160 |
| فریم ریٹ | 30-120 fps |
| فیلڈ آف ویو | 60°-180° |
| ڈیپتھ رینج | 0.3-10 m |

#### لائیڈار (Light Detection and Ranging)

لائیڈار فاصلے ناپنے کے لیے لیزر پلسز استعمال کرتا ہے۔

**کام کا اصول:**
1. لیزر پلس emit کریں
2. پلس اشیاء سے منعکس ہو
3. واپسی کا وقت ناپیں
4. فاصلے کا حساب لگائیں: $d = \frac{c \cdot t}{2}$

**اقسام:**
- **2D لائیڈار**: واحد سکیننگ plane
- **3D لائیڈار**: متعدد planes یا گھومنے والا head

**فوائد:**
- زیادہ accuracy (±1-3 cm)
- لمبی رینج (100+ m تک)
- مختلف روشنی کے حالات میں کام کرتا ہے

**حدود:**
- شفاف/منعکس سطحوں سے مشکلات
- کیمروں سے زیادہ مہنگا
- کیمروں سے کم ریزولوشن

#### ٹیکٹائل سینسرز

ٹیکٹائل سینسرز روبوٹس کو رابطے اور texture "محسوس" کرنے کے قابل بناتے ہیں۔

**ٹیکنالوجیز:**

1. **رزسٹو**: پریشر الیکٹریکل resistance بدلتا ہے
2. **کیپیسیٹو**: پریشر capacitance بدلتا ہے
3. **پیزوالیکٹرک**: پریشر سے وولٹیج پیدا کرتا ہے
4. **آپٹیکل**: deformation کا پتہ لگانے کے لیے روشنی استعمال کرتا ہے

**ٹیکٹائل Arrays:**
- انگلیوں یا ہتھیلیوں پر گرڈز میں ترتیب دیے گئے
- ریزولوشن: 1-5 mm فاصلہ
- سینسیٹویٹی: 0.01-1 N

**BioTac اور مشابہ:**
ایڈوانسڈ سینسرز جو انسانی انگلی کی نقل کرتے ہیں:
- فورس، vibration، temperature کا پتہ لگاتے ہیں
- compliance کے لیے fluid سے بھرے

#### پراکسیمیٹی سینسرز

بغیر رابطے کے اشیاء کا پتہ لگاتے ہیں۔

**الٹراسونک سینسرز:**
- ساؤنڈ ویوز استعمال کرتے ہیں (40-200 kHz)
- رینج: 2 cm سے 5 m
- کم قیمت، کم ریزولوشن

**انفراریڈ سینسرز:**
- IR روشنی emit اور detect کرتے ہیں
- مختصر رینج (1 cm سے 1 m)
- ambient روشنی سے متاثر

## سینسر فیوژن

متعدد سینسرز سے ڈیٹا کو ملانا reliability اور accuracy بہتر کرتا ہے۔

### سینسر فیوژن کیوں؟

- **تکمیلی**: مختلف سینسرز مختلف معلومات capture کرتے ہیں
- **redundant**: ایک ہی مقدار ناپنے والے متعدد سینسرز reliability بڑھاتے ہیں
- **تعاونی**: ساتھ کام کرنے والے سینسرز وہ ناپ سکتے ہیں جو کوئی اکیلا نہیں ناپ سکتا

### کالمن فلٹر

کالمن فلٹر سینسر فیوژن کا بنیادی الگورتھم ہے۔

**State Estimation:**
نوائزی measurements سے hidden state کا تخمینہ لگاتا ہے۔

**دو مراحل:**
1. **پیش گوئی**: اگلی state کی پیش گوئی کے لیے موشن ماڈل استعمال کریں
2. **اپڈیٹ**: نئی measurement شامل کریں

**مساواتیں:**
```
پیش گوئی:
  x̂ₖ|ₖ₋₁ = Fₖx̂ₖ₋₁|ₖ₋₁ + Bₖuₖ
  Pₖ|ₖ₋₁ = FₖPₖ₋₁|ₖ₋₁Fₖᵀ + Qₖ

اپڈیٹ:
  Kₖ = Pₖ|ₖ₋₁Hₖᵀ(HₖPₖ|ₖ₋₁Hₖᵀ + Rₖ)⁻¹
  x̂ₖ|ₖ = x̂ₖ|ₖ₋₁ + Kₖ(zₖ - Hₖx̂ₖ|ₖ₋₁)
  Pₖ|ₖ = (I - KₖHₖ)Pₖ|ₖ₋₁
```

### ایکسٹینڈڈ کالمن فلٹر (EKF)

نان لینیئر سسٹمز کے لیے، موجودہ estimate کے گرد linearize کریں:
- F کو موشن ماڈل کے جیکوبین سے بدلیں
- H کو measurement ماڈل کے جیکوبین سے بدلیں

### پارٹیکل فلٹرز

انتہائی نان لینیئر یا multimodal distributions کے لیے:
- belief کو weighted particles سے represent کریں
- سیمپل کریں، weight دیں، resample کریں
- زیادہ flexible لیکن computationally مہنگے

## روبوٹکس کے لیے کمپیوٹر ویژن

### امیج پراسیسنگ کی بنیادیں

**کلر سپیسز:**
- RGB: Red، Green، Blue
- HSV: Hue، Saturation، Value (رنگ کی تشخیص کے لیے بہتر)
- Grayscale: واحد intensity چینل

**عام آپریشنز:**
- **فلٹرنگ**: smoothing، edge detection (Sobel، Canny)
- **مارفولوجی**: Erosion، dilation، opening، closing
- **سیگمینٹیشن**: Thresholding، clustering، region growing

### آبجیکٹ ڈیٹیکشن اور ریکگنیشن

**روایتی طریقے:**
1. فیچر extraction (SIFT، SURF، ORB)
2. فیچر matching
3. ماڈل fitting

**ڈیپ لرننگ طریقے:**
- **CNN پر مبنی**: YOLO، SSD، Faster R-CNN
- **ریئل ٹائم قابل**: GPU پر 30+ fps
- **زیادہ accuracy**: معیاری بینچ مارکس پر 80-90%+ mAP

### پوز Estimation

تصاویر سے آبجیکٹ یا انسانی پوز کا تعین۔

**آبجیکٹ پوز:**
- 6-DOF: 3 پوزیشن + 3 اورینٹیشن
- طریقے: PnP، ICP، لرننگ پر مبنی

**ہیومن پوز:**
- کیپوائنٹ ڈیٹیکشن (OpenPose، MediaPipe)
- فل باڈی میش estimation (SMPL)
- ایپلیکیشنز: ہیومن-روبوٹ تعامل، موشن capture

### ویژول SLAM

ویژن استعمال کرتے ہوئے Simultaneous Localization and Mapping۔

**عمل:**
1. کیمرا تصاویر سے visual features extract کریں
2. فریمز میں features کو track کریں
3. کیمرا موشن کا تخمینہ لگائیں (Visual Odometry)
4. نقشہ بنائیں اور اپڈیٹ کریں
5. loop closures کا پتہ لگائیں
6. trajectory اور نقشے کو optimize کریں

**مقبول سسٹمز:**
- ORB-SLAM3
- LSD-SLAM
- RTAB-Map

## ڈیپتھ پرسیپشن

### سٹیریو ویژن

گہرائی کا حساب لگانے کے لیے دو کیمرے استعمال کرنا۔

**جیومیٹری:**
```
      بایاں    دایاں
      کیمرا    کیمرا
        ●--------●
        |   b    |
        |        |
      fl|      fr|
        |        |
        +---------+
              آبجیکٹ
```

**ڈسپیریٹی:**
$d = x_L - x_R$

**ڈیپتھ:**
$Z = \frac{f \cdot b}{d}$

جہاں:
- $f$ focal length ہے
- $b$ baseline ہے (کیمروں کے درمیان فاصلہ)
- $d$ disparity ہے

### سٹرکچرڈ لائٹ

معلوم پیٹرن پروجیکٹ کریں اور distortion کا تجزیہ کریں۔

**عمل:**
1. پیٹرن پروجیکٹ کریں (dots، lines، grids)
2. deformed پیٹرن کی تصویر capture کریں
3. depth کا حساب لگانے کے لیے reference سے موازنہ کریں

**مثال:** Intel RealSense D4xx سیریز

### ٹائم آف فلائٹ

روشنی کے سفر کا وقت براہ راست ناپیں۔

**Phase-based ToF:**
- روشنی کی amplitude modulate کریں
- واپسی کی phase shift ناپیں
- رینج modulation frequency سے محدود

**مثال:** Microsoft Azure Kinect

## ہیومنائڈز میں سینسر انٹیگریشن

### سر کے سینسرز
- ویژن کے لیے سٹیریو کیمرے
- سر کی orientation کے لیے IMU
- آڈیو کے لیے مائیکروفون

### جسم کے سینسرز
- توازن کے لیے دھڑ IMU
- پورے جسم میں جوائنٹ انکوڈرز
- کلائیوں اور ٹخنوں پر فورس/ٹارک

### ہاتھ کے سینسرز
- انگلیوں پر ٹیکٹائل arrays
- انگلیوں میں جوائنٹ انکوڈرز
- پکڑ کے لیے فورس سینسرز

### پاؤں کے سینسرز
- گراؤنڈ ری ایکشن کے لیے فورس/ٹارک
- پریشر distribution سینسرز
- کانٹیکٹ سوئچز

## چیلنجز اور مستقبل کی سمتیں

### موجودہ چیلنجز
1. **سینسر نوائز اور ڈرفٹ**: محتاط calibration اور filtering کی ضرورت
2. **ریئل ٹائم پراسیسنگ**: ہائی بینڈوڈتھ سینسر ڈیٹا کو تیز پراسیسنگ کی ضرورت
3. **سینسر فیوژن پیچیدگی**: متنوع modalities کا انضمام مشکل ہے
4. **لاگت**: اعلیٰ معیار کے سینسرز مہنگے رہتے ہیں

### ابھرتی ٹیکنالوجیز
- **ایونٹ کیمرے**: الٹرا ہائی اسپیڈ ویژن
- **نیورومورفک سینسرز**: دماغ سے متاثر سینسنگ
- **سافٹ سینسرز**: مڑی ہوئی سطحوں کے مطابق
- **خود calibrating سسٹمز**: maintenance کا بوجھ کم کریں

## خلاصہ

روبوٹ سینسنگ میں ٹیکنالوجیز کی وسیع صف شامل ہے:
- پروپریوسیپٹو سینسرز اندرونی حالت ناپتے ہیں
- ایکسٹروسیپٹو سینسرز ماحول کو محسوس کرتے ہیں
- سینسر فیوژن مضبوط estimation کے لیے متعدد ذرائع کو جوڑتا ہے
- کمپیوٹر ویژن بصری معلومات کی سمجھ ممکن بناتا ہے
- ڈیپتھ پرسیپشن 3D ماحولیاتی آگاہی فراہم کرتا ہے

مؤثر سینسر انٹیگریشن ہیومنائڈ روبوٹس کے انسانی ماحول میں محفوظ اور مؤثر طریقے سے کام کرنے کے لیے ضروری ہے۔

## اہم تصورات

| سینسر کی قسم | ناپتا ہے | اہم specifications |
|-------------|----------|-------------------|
| انکوڈر | جوائنٹ زاویہ | ریزولوشن (CPR) |
| IMU | اورینٹیشن، acceleration | ڈرفٹ ریٹ، نوائز |
| F/T سینسر | فورس، ٹارک | رینج، ریزولوشن |
| کیمرا | بصری منظر | ریزولوشن، فریم ریٹ |
| لائیڈار | فاصلہ | رینج، accuracy |
| ٹیکٹائل | رابطہ، پریشر | ریزولوشن، سینسیٹویٹی |

## جائزہ سوالات

1. پروپریوسیپٹو اور ایکسٹروسیپٹو سینسرز میں کیا فرق ہے؟
2. کالمن فلٹر پیش گوئیوں کو measurements کے ساتھ کیسے جوڑتا ہے؟
3. سٹیریو disparity اور depth کے درمیان تعلق واضح کریں۔
4. روبوٹ پرسیپشن کے لیے سینسر فیوژن کیوں اہم ہے؟
